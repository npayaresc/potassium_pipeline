"""
SHAP-Based Feature Selection Module

This module provides feature selection based on SHAP (SHapley Additive exPlanations)
importance rankings. It allows training models with only the most important features
identified through SHAP analysis.
"""

import logging
from typing import Optional, List
from pathlib import Path
import numpy as np
import pandas as pd
from sklearn.base import BaseEstimator, TransformerMixin

logger = logging.getLogger(__name__)


class SHAPBasedFeatureSelector(BaseEstimator, TransformerMixin):
    """
    Feature selector that uses SHAP importance rankings to select top N features.

    This selector loads a SHAP importance CSV file (generated by analyze_feature_importance.py)
    and selects the top N most important features based on SHAP values.

    Parameters:
    -----------
    shap_importance_file : str
        Path to SHAP importance CSV file (e.g., models/model_name_shap_importance.csv)
    top_n : int, default=30
        Number of top features to select based on SHAP importance
    min_importance : float, optional
        Minimum SHAP importance threshold. If specified, only features with
        importance >= min_importance will be selected (in addition to top_n constraint)

    Attributes:
    -----------
    feature_names_ : list
        Names of all input features
    selected_features_ : np.ndarray
        Boolean mask indicating which features are selected
    shap_importance_ : pd.DataFrame
        DataFrame with feature names and SHAP importance scores
    selected_feature_names_ : list
        Names of selected features

    Example:
    --------
    >>> # After running SHAP analysis
    >>> selector = SHAPBasedFeatureSelector(
    ...     shap_importance_file='models/simple_only_xgboost_20251006_shap_importance.csv',
    ...     top_n=30
    ... )
    >>> X_selected = selector.fit_transform(X_train)
    >>> print(f"Selected {selector.n_features_selected_} features")
    """

    def __init__(
        self,
        shap_importance_file: str,
        top_n: int = 30,
        min_importance: Optional[float] = None
    ):
        self.shap_importance_file = shap_importance_file
        self.top_n = top_n
        self.min_importance = min_importance

        # Will be set during fit
        self.feature_names_ = None
        self.selected_features_ = None
        self.shap_importance_ = None
        self.selected_feature_names_ = None
        self.n_features_selected_ = 0

    def fit(self, X, y=None):
        """
        Fit the feature selector by loading SHAP importance and identifying top features.

        Parameters:
        -----------
        X : array-like or DataFrame of shape (n_samples, n_features)
            Training data
        y : array-like, optional
            Target values (not used, present for sklearn compatibility)

        Returns:
        --------
        self : object
            Fitted transformer
        """
        # Store feature names
        if isinstance(X, pd.DataFrame):
            self.feature_names_ = list(X.columns)
        else:
            self.feature_names_ = [f"feature_{i}" for i in range(X.shape[1])]

        # Load SHAP importance file
        shap_file = Path(self.shap_importance_file)
        if not shap_file.exists():
            raise FileNotFoundError(
                f"SHAP importance file not found: {self.shap_importance_file}\n"
                f"Run SHAP analysis first: ./run_shap_analysis.sh <model_path>"
            )

        logger.info(f"Loading SHAP importance from: {shap_file.name}")
        self.shap_importance_ = pd.read_csv(shap_file)

        # Validate required columns
        if 'feature' not in self.shap_importance_.columns or 'shap_importance' not in self.shap_importance_.columns:
            raise ValueError(
                f"SHAP importance file must contain 'feature' and 'shap_importance' columns. "
                f"Found: {list(self.shap_importance_.columns)}"
            )

        # Get top N features based on SHAP importance
        # The CSV is already sorted by importance (descending)
        top_features_df = self.shap_importance_.head(self.top_n).copy()

        # Apply minimum importance threshold if specified
        if self.min_importance is not None:
            top_features_df = top_features_df[
                top_features_df['shap_importance'] >= self.min_importance
            ]
            logger.info(
                f"Applied min_importance threshold ({self.min_importance}), "
                f"kept {len(top_features_df)} features"
            )

        # Get selected feature names from SHAP file
        shap_selected_features = top_features_df['feature'].tolist()

        # Validate that selected features exist in current data
        available_features = set(self.feature_names_)
        shap_features_set = set(shap_selected_features)

        # Find which SHAP features exist in current data
        valid_features = [f for f in shap_selected_features if f in available_features]
        missing_features = [f for f in shap_selected_features if f not in available_features]

        if missing_features:
            logger.warning(
                f"\n‚ö†Ô∏è  SHAP FEATURE MISMATCH DETECTED:\n"
                f"  - {len(missing_features)}/{len(shap_selected_features)} SHAP features not found in current data\n"
                f"  - This likely means the SHAP analysis was done on a different feature strategy\n"
                f"  - Using only the {len(valid_features)} matching features"
            )
            if len(valid_features) < 5:
                logger.error(
                    f"\n‚ùå CRITICAL: Only {len(valid_features)} SHAP features found in current data!\n"
                    f"   SHAP file appears to be from a different feature strategy.\n"
                    f"   First 5 missing features: {missing_features[:5]}\n"
                    f"   First 5 available features: {list(available_features)[:5]}"
                )
                raise ValueError(
                    f"SHAP feature mismatch: Only {len(valid_features)}/{len(shap_selected_features)} "
                    f"features from SHAP file exist in current data. "
                    f"The SHAP importance file appears to be from a different feature engineering strategy. "
                    f"Please run SHAP analysis on a model trained with the current strategy."
                )

            logger.warning(f"  First 5 missing: {missing_features[:5]}")

        self.selected_feature_names_ = valid_features
        self.n_features_selected_ = len(self.selected_feature_names_)

        # Create boolean mask for selected features
        self.selected_features_ = np.array([
            fname in self.selected_feature_names_ for fname in self.feature_names_
        ])

        # Log selection summary
        logger.info("="*80)
        logger.info("SHAP-BASED FEATURE SELECTION")
        logger.info("="*80)
        logger.info(f"SHAP importance file: {shap_file.name}")
        logger.info(f"Total features available: {len(self.feature_names_)}")
        logger.info(f"Top N requested: {self.top_n}")
        logger.info(f"Features selected: {self.n_features_selected_}")

        if self.n_features_selected_ < self.top_n:
            logger.warning(
                f"‚ö†Ô∏è  Only {self.n_features_selected_} features selected "
                f"(requested {self.top_n}). "
                f"This may occur if min_importance threshold is too high or "
                f"SHAP file contains fewer features."
            )

        # Log top 10 selected features (only those that exist in current data)
        valid_features_df = top_features_df[top_features_df['feature'].isin(valid_features)].head(10)
        logger.info(f"\nTop 10 selected features by SHAP importance:")
        for i, row in valid_features_df.iterrows():
            rank = i + 1
            logger.info(
                f"  {rank:2d}. {row['feature']:<50} "
                f"SHAP={row['shap_importance']:.6f} "
                f"({row.get('%_of_total', 0):.2f}%)"
            )

        if self.n_features_selected_ > 10:
            logger.info(f"  ... and {self.n_features_selected_ - 10} more features")

        # Calculate cumulative importance (only for valid features)
        total_importance = self.shap_importance_['shap_importance'].sum()
        valid_features_df = top_features_df[top_features_df['feature'].isin(valid_features)]
        selected_importance = valid_features_df['shap_importance'].sum()
        cumulative_pct = (selected_importance / total_importance) * 100

        logger.info(f"\nüìä Selection Statistics:")
        logger.info(f"  Selected features cover {cumulative_pct:.1f}% of total SHAP importance")
        logger.info("="*80)

        return self

    def transform(self, X):
        """
        Transform X by selecting only the top N features identified by SHAP.

        Parameters:
        -----------
        X : array-like or DataFrame of shape (n_samples, n_features)
            Input data

        Returns:
        --------
        X_selected : array-like or DataFrame of shape (n_samples, n_features_selected)
            Data with only selected features
        """
        if self.selected_features_ is None:
            raise ValueError("Feature selector has not been fitted yet. Call fit() first.")

        # Check feature count matches
        if X.shape[1] != len(self.feature_names_):
            raise ValueError(
                f"Feature count mismatch: X has {X.shape[1]} features, "
                f"but selector was fitted with {len(self.feature_names_)} features"
            )

        if isinstance(X, pd.DataFrame):
            # For DataFrame, select columns by name
            return X[self.selected_feature_names_]
        else:
            # For numpy array, select columns by boolean mask
            return X[:, self.selected_features_]

    def fit_transform(self, X, y=None):
        """
        Fit the selector and transform X in one step.

        Parameters:
        -----------
        X : array-like or DataFrame of shape (n_samples, n_features)
            Training data
        y : array-like, optional
            Target values

        Returns:
        --------
        X_selected : array-like or DataFrame of shape (n_samples, n_features_selected)
            Transformed data with selected features
        """
        return self.fit(X, y).transform(X)

    def get_feature_names_out(self, input_features=None):
        """
        Get names of selected features.

        Parameters:
        -----------
        input_features : array-like, optional
            Input feature names (not used, present for sklearn compatibility)

        Returns:
        --------
        feature_names_out : np.ndarray
            Names of selected features
        """
        if self.selected_feature_names_ is None:
            raise ValueError("Feature selector has not been fitted yet. Call fit() first.")

        return np.array(self.selected_feature_names_)

    def get_support(self, indices=False):
        """
        Get a mask or integer index of selected features.

        Parameters:
        -----------
        indices : bool, default=False
            If True, return integer indices of selected features.
            If False, return boolean mask.

        Returns:
        --------
        support : np.ndarray
            Boolean mask or integer indices of selected features
        """
        if self.selected_features_ is None:
            raise ValueError("Feature selector has not been fitted yet. Call fit() first.")

        if indices:
            return np.where(self.selected_features_)[0]
        else:
            return self.selected_features_

    def get_shap_importance_df(self) -> pd.DataFrame:
        """
        Get the full SHAP importance DataFrame (all features, sorted by importance).

        Returns:
        --------
        shap_importance : pd.DataFrame
            DataFrame with columns: feature, shap_importance, %_of_total, cumulative_%
        """
        if self.shap_importance_ is None:
            raise ValueError("Feature selector has not been fitted yet. Call fit() first.")

        return self.shap_importance_.copy()

    def get_selected_features_df(self) -> pd.DataFrame:
        """
        Get DataFrame with selected features and their SHAP importance.

        Returns:
        --------
        selected_df : pd.DataFrame
            DataFrame with selected features, sorted by SHAP importance
        """
        if self.shap_importance_ is None or self.selected_feature_names_ is None:
            raise ValueError("Feature selector has not been fitted yet. Call fit() first.")

        # Filter to selected features only
        selected_df = self.shap_importance_[
            self.shap_importance_['feature'].isin(self.selected_feature_names_)
        ].copy()

        return selected_df
